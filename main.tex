\documentclass[unicode,12pt,aspectratio=169,dvipdfmx]{beamer}
\usepackage{bxdpx-beamer}
\usetheme[progressbar=frametitle]{metropolis}
\renewcommand{\kanjifamilydefault}{\gtdefault}
\usepackage{bm}
\title{\textbf{介護における音響HARと連合学習を用いた異常検知}}
\author{\textbf{竹本志恩}}
\institute{\textbf{INIAD}}
\date{\today}
% セクション開始時にミニTOC
% \AtBeginSection[]{
%   \begin{frame}[plain]
%     \frametitle{目次}
%     \tableofcontents[currentsection, hideallsubsections]
%   \end{frame}
% }
\begin{document}
%----------------------------------------
% 本編スライド
%----------------------------------------
% Slide 1: Title
\begin{frame}
  \titlepage
\end{frame}
% Slide 2: Agenda
% \begin{frame}{アジェンダ}
%   \begin{enumerate}
%     \item 背景・研究目的
%     \item 本研究の独自性
%     \item 音響HARの基礎と課題
%     \item FLの基礎とHARへの適用
%     \item FL-HARの主要課題
%     \item 課題解決の戦略
%     \item 関連研究動向
%     \item 今後の展望
%     \item まとめ・Q\&A
%   \end{enumerate}
% \end{frame}
% Slide 3: Background & Objectives
% \section{背景・研究目的}
\begin{frame}{背景と研究目的}
  \begin{itemize}
    \item 高齢化社会における介護現場の負担増大
    \item HARに着目: 介護者の負担軽減
    \item センサデータのプライバシー懸念にFLで対処
    \item 目的：FLで異常イベントをリアルタイム検知＋通知
  \end{itemize}
\end{frame}
% Slide 4: Uniqueness
% \section{本研究の独自性}
\begin{frame}{本研究の独自性}
  \begin{itemize}
    \item 複数の異常イベントを同時／複合的に検知
    \item マルチラベル分類で音響イベントを解釈
    \begin{itemize}
        \item 画像中のりんごとバナナを識別
        \item 咳と苦痛の声が同時に聞こえる$>$重篤な状態
        \item 転倒に似た音を,他のイベントを基に判断
    \end{itemize}
    \item マルチラベルイベント検知 + 異常検知
    \begin{itemize}
        \item どの時間帯に、何のイベントが、どういう組で起こったか識別
        \item 深い状況把握と迅速対応を実現
    \end{itemize}


  \end{itemize}
\end{frame}
% Slide 5: Acoustic HAR Basics
% \section{音響HARの基礎と課題}
\begin{frame}{音響HARの課題}
  \begin{itemize}
    \item 利点: 非接触モニタリング＋視覚プライバシー保護
    \item 課題
    \begin{itemize}
        \item 環境騒音によるマスキング
        \item 高静音性活動の検知が困難
        \item 音の多様性／同時発生の問題
    \end{itemize}
    \item 頑健なモデルが必要
  \end{itemize}
\end{frame}
% Slide 6: FL Basics & Benefits
% \section{FLの基礎とHAR適用}
\begin{frame}{連合学習 (FL) の基礎とHARへの適用}
  \begin{itemize}
    \item 分散学習：生データ非共有でモデル協調学習
    \item プライバシー保護、パーソナル化、通信効率
    \item 介護現場に適した技術
  \end{itemize}
\end{frame}
% Slide 7: Challenges I (Data)
\section{FL-HARの主要課題}
\begin{frame}{主要課題①：データ関連}
\begin{itemize}
  \item 極端なデータ不均衡（稀イベント、多ラベル共起）
    \begin{itemize}
      \item 複数異常の組み合わせはほぼない
    \end{itemize}
  \item Non-IID分布
    \begin{itemize}
      \item 各利用者の音響特性や行動の差
    \end{itemize}
  \item ラベルの関係を捉えたモデリング
  \item マルチラベルデータセットの不足
\end{itemize}
\end{frame}

% Slide 8: Challenges II (Model, Comm, Privacy)
\begin{frame}{主要課題②：モデル・通信・プライバシー}
  \begin{itemize}
    \item モデル複雑化 \(\leftrightarrow\)  通信オーバーヘッド
    \item リアルタイム通知の遅延リスク
    \begin{itemize}
        \item イベント検知\(\rightarrow\)異常検知の手順を検討中
        \item 段階的な処理は推論速度が低下しそう
    \end{itemize}
    \item マルチラベルによるプライバシリスクの上昇
    \begin{itemize}
        \item マルチクラスより情報が増加
    \end{itemize}
\end{itemize}
\end{frame}
% Slide 9: Challenges III (Personalization & CL)
\begin{frame}{主要課題③：パーソナライズ化・継続学習}
  \begin{itemize}
    \item 個人差対応のパーソナライズドFL
    \item コールドスタート：未知の音響組み合わせ
    \item 音響環境変化への適応
  \end{itemize}
\end{frame}
% Slide 10: Strategy I (Data & Non-IID)
\section{課題解決の戦略}

% マルチラベルの解説がないのでは?

\begin{frame}{対策①：データ不均衡・Non-IID対策}
  \begin{itemize}
    \item 合成データ生成 (GAN, SMOTE)
    \item 少数クラスを強調: Time-Balanced Focal Loss\cite{TBFL} など特殊損失
    \item 集約法の工夫: FedProx\cite{FedProx}など
    \item モデル統合の効率化: クラスタリングFL／ドメイン適応
  \end{itemize}
\end{frame}
% Slide 11: Strategy II (Privacy)
% \begin{frame}{対策②：プライバシー強化}
%   \begin{itemize}
%     \item オンデバイス特徴抽出によるデータ最小化
%     \item ノイズ付与: 差分プライバシー (DP)
%     \item 暗号化集約: セキュアアグリゲーション (SA)／同型暗号 (HE)
%     \item 精度とオーバーヘッドのバランス
%   \end{itemize}
% \end{frame}

% Slide 12: Strategy III (Model & Efficiency)
\begin{frame}{対策③：モデル・リソース効率化}
  \begin{itemize}
    \item モデル軽量化: モデル圧縮/量子化/枝刈り
    \item 計算の分割: Federated Split Learning (FSL)\cite{FSL}
    \item 通信量削減: 勾配圧縮・選択的更新
    % \item マルチモーダル融合戦略
  \end{itemize}
\end{frame}
% Slide 13: Related Work
% \section{関連研究動向}
\begin{frame}{関連研究：マルチラベルFL}
  \begin{itemize}
    \item マルチラベルFLフレームワークが存在
    \item 例: FMLL\cite{FMLL}, FedMLP\cite{FedMLP}, FedLGT\cite{FedLGT}
    \item 参考になりそう
  \end{itemize}
\end{frame}
% Slide 14: Future Directions
% \section{今後の展望}
\begin{frame}{今後の展望}
  \begin{itemize}
    \item 標準化データセットの整備
    \item FL対応マルチラベル損失/新アーキテクチャ開発

    $|-$マルチラベルFLなど参考
    % \item 連合継続学習・因果推論の検討
  \end{itemize}
\end{frame}
% Slide 15: Conclusion & Q&A
% \section{まとめ・結論}
% \begin{frame}{まとめ}
%   \begin{itemize}
%     \item マルチラベル異常検知FL-HARの可能性
%     \item 主要課題と解決の方向性
%     \item 社会実装へのロードマップ
%   \end{itemize}
%   \vfill
% \end{frame}
%----------------------------------------
% 補足資料スライド (配布用)
%----------------------------------------
% \appendix 

% \section{補足資料}
% \subsection{データ不均衡・Non-IIDへの対応}
% \begin{frame}{データ不均衡・Non-IIDへの対応：SMOTE}
% \begin{itemize}
%     \item \textbf{概要}：\textbf{Synthetic Minority Over-sampling Technique}の略
%     \item \textbf{目的}：\textbf{少数クラスのデータ不足}に起因する不均衡を緩和
%     \item \textbf{動作原理}：既存の少数サンプル間の特徴空間で補間することで、\textbf{合成サンプルを生成}。音響データの場合、MFCCなどの\textbf{抽出された音響特徴量}に適用
%     \item \textbf{利点と課題}：
%     \begin{itemize}
%         \item 実装が比較的容易で、多くのライブラリで利用可能
%         \item 単純な適用では\textbf{過学習}の可能性
%         \item 音響的に意味のある合成サンプルを生成できない、時間的連続性が破壊される可能性も
%         \item \textbf{希少イベント固有の音響特性}を保持することが重要
%     \end{itemize}
% \end{itemize}
% \end{frame}

% \begin{frame}{データ不均衡・Non-IIDへの対応：Time-Balanced Focal Loss \cite{TBFL}}
% \begin{itemize}
%     \item \textbf{概要}：持続時間のばらつきによるデータ不均衡を考えた損失関数
%     \item \textbf{目的}：イベントの発生頻度だけでなく、\textbf{持続時間も考慮}
%     \item \textbf{動作原理}：
%     \begin{itemize}
%         \item 標準的なFocal Lossをクラスごとの重み $w_c$で拡張
%         \item $w_c$は、データ量（音源/クリップ数）とイベント持続時間（フレームの比率$r_c$）を考慮
%         \item \textbf{希少で持続時間の短い音響イベントの学習が強化され、検出精度が向上}
%         % \item 式は以下
%         %     \begin{equation*}
%         %     \text{TBFL}(p,y) = -\sum_{c} w_c \left\{ y_c (1-p_c)^\gamma \log(p_c) + (1-y_c) p_c^\gamma \log(1-p_c) \right\}
%         %     \end{equation*}
%         %     ここで、$w_c \propto \frac{1-\beta^{c k} \times r_c}{1-\beta^{c}}$であり、$\sum_c w_c = C$（$C$はターゲットクラス数）です。
%     \end{itemize}
% \end{itemize}
% \end{frame}

% \begin{frame}{データ不均衡・Non-IIDへの対応：ドメイン適応}
% \begin{itemize}
%     \item \textbf{概要}：\textbf{異なるデータ分布（ドメイン）間}でのモデルの汎化能力を高めるための技術です [16, 23]。
%     \item \textbf{目的}：Federated Learningにおいて、\textbf{クライアントごとのデータ分布が異なるNon-IID問題}に対処し、モデルの適応性を向上させます [16, 24]。
%     \item \textbf{動作原理}：
%     \begin{itemize}
%         \item データセット内の\textbf{位相的構造（topological structures）を整合させる}ことにより、限られたラベル付きデータでの性能を向上させます [24]。
%         \item \textbf{クラスタリングFL}（類似したデータ分布や異常パターンを持つクライアントをグループ化し、グループごとにモデルを学習させるアプローチ）もNon-IIDデータへの対応戦略として挙げられています [16, 17, 25]。
%         \item ClusterFLは、\textbf{類似性認識型連合学習システム}としてHARの異質性に対処します [25]。
%     \end{itemize}
% \end{itemize}
% \end{frame}

% \subsection{プライバシー強化技術}
% \begin{frame}{プライバシー強化技術：差分プライバシー (DP)}
% \begin{itemize}
%     \item \textbf{目的}：個々のデータサンプルの寄与を曖昧にし、漏洩リスクを保証
%     \item \textbf{動作原理}：
%     \begin{itemize}
%         \item モデル更新（勾配や重みなど）に\textbf{ノイズを付加}
%         \item Federated Split Learning (FSL) では、中間活性化情報に\textbf{ガウスノイズ}
%     \end{itemize}
%     \item \textbf{課題}：以下のトレードオフ
%     \begin{itemize}
%         \item モデルの精度低下
%         \item 計算・通信オーバーヘッドの増加
%     \end{itemize}
% \end{itemize}
% \end{frame}

% \begin{frame}{プライバシー強化技術：セキュアアグリゲーション (SA)}
% \begin{itemize}
%     \item \textbf{概要}：Federated Learningにおける\textbf{プライバシー強化技術（PETs）}の一つです [16, 23, 26]。
%     \item \textbf{目的}：各クライアントからのモデル更新を、\textbf{個々の更新内容をサーバーに知られることなく集約}することを目指します [16, 26]。
%     \item \textbf{動作原理}：複数のクライアントからのモデルパラメータを安全に結合し、サーバーは最終的な集約結果のみを得る仕組みを提供します [26]。
%     \item \textbf{利点と課題}：
%     \begin{itemize}
%         \item サーバーによる\textbf{個別のクライアントデータ推論のリスクを低減}し、プライバシー保護に貢献します [26]。
%         \item しかし、\textbf{学習時間が長くなる}可能性があると指摘されています [27]。
%     \end{itemize}
% \end{itemize}
% \end{frame}

% \begin{frame}{プライバシー強化技術：準同型暗号 (HE)}
% \begin{itemize}
%     \item \textbf{目的}：\textbf{暗号化されたデータに対して直接計算を実行}することを可能にし、元のデータを復号することなくモデルを訓練
%     \item \textbf{動作原理}：クライアントは自身のデータを暗号化してモデル更新を送信し、サーバーは暗号化された更新をそのまま集約し、その結果も暗号化されたままクライアントに返す。復号はクライアント側で実施
%     \item \textbf{利点と課題}：
%     \begin{itemize}
%         \item \textbf{非常に強固なプライバシー保護}を提供します [26]。
%         \item しかし、\textbf{計算コストや通信オーバーヘッドが非常に高い}傾向があり [26]、モデルの\textbf{精度低下とのトレードオフ}も考慮する必要があります [26]。
%     \end{itemize}
% \end{itemize}
% \end{frame}

% \subsection{リソース効率化技術}
% \begin{frame}{リソース効率化技術：Federated Split Learning (FSL)\cite{FSL}}
% \begin{itemize}
%     \item \textbf{概要}：\textbf{モデルの計算負荷をクライアントとサーバーで分割}
%     \item \textbf{目的}：\textbf{エッジデバイスの計算能力、メモリ、通信帯域の制約を両立}させながら、モデル訓練や推論を効率的に実行
%     \item \textbf{動作原理}：
%     \begin{itemize}
%         \item モデルの層を分割点（\textbf{`cut layer`}または\textbf{`split layer`}）で分け、\textbf{クライアント側でモデルの一部（例：特徴抽出層）を処理}し、\textbf{中間活性化情報}をサーバーに送信
%         \item \textbf{サーバー側で残りのモデル処理（例：分類層）、損失計算、およびバックプロパゲーションを実行}
%         \item 例: クライアント側にLSTM層、サーバー側に出力層（Dense+Softmax）を配置
%     \end{itemize}
% \end{itemize}
% \end{frame}

% % \subsection{マルチラベルFLフレームワークの概要とHAR適用課題}
% \begin{frame}{マルチラベルFLフレームワーク：FMLL\cite{FMLL}}
% \begin{itemize}
%     \item \textbf{動作原理}：
%     \begin{itemize}
%         \item マルチラベルデータセットを\textbf{バイナリ関連性 (Binary Relevance) 戦略}に基づき複数の二値データセットに分解
%         \item 各二値データセットで\textbf{ローカルモデル（例: REPTree）を訓練}し、中央ノードでこれらのローカルモデルを\textbf{集約}してグローバルモデルを作成
%     \end{itemize}
%     \item \textbf{HAR適用時の課題}：
%     \begin{itemize}
%         \item 現状、\textbf{動物科学分野のデータセット}で検証されており [33, 35]、\textbf{HAR異常データへの直接的な適用性は未検証}
%         \item ベース分類器としてREPTreeを使用しており,表現力の限界が懸念
%     \end{itemize}
% \end{itemize}
% \end{frame}

% \begin{frame}{マルチラベルFLフレームワーク：FedMLP\cite{FedMLP}}
% \begin{itemize}
%     \item \textbf{概要}：{部分的なアノテーション（欠損ラベル）を持つマルチラベルFL}に対応
%     % \item \textbf{動作原理}：
%     % \begin{itemize}
%     %     \item \textbf{第1段階}：ウォームアップモデルで\textbf{クラスプロトタイプを生成}し、自己適応型閾値 (ST) による\textbf{疑似ラベリングを用いて欠損ラベルを補完}します [38-41]。クラス不均衡には重み付き部分クラス (WPC) 損失とロジット調整を使用します [38, 39, 41, 42]。
%     %     \item \textbf{第2段階}：\textbf{グローバルモデルを教師}とし、\textbf{整合性正則化}を行うことで、欠損クラス知識の忘却を防ぎます [38-40]。
%     % \end{itemize}
%     \item \textbf{HAR適用時の課題}：
%     \begin{itemize}
%         \item 医療データセットで検証されている
%         \item \textbf{疑似ラベリングの精度が全体の性能に影響を与える}可能性
%     \end{itemize}
% \end{itemize}
% \end{frame}

% \begin{frame}{マルチラベルFLフレームワーク：FedLGT\cite{FedLGT}}
% \begin{itemize}
%     \item 異なるラベル関連性や、陽性ラベルセットの不整合があっても\textbf{堅牢なグローバルモデルを学習}
%     \item \textbf{動作原理}：
%     \begin{itemize}
%         \item \textbf{Universal Label Embedding}: CLIPのような事前学習済みテキストエンコーダで、ラベルの関係係を捉える
%         \item \textbf{Client-Aware Masked Label Embedding}：グローバルモデルからの知識を転移し、ローカルモデルがグローバルモデルの信頼度が低いクラスについてより多く学習
%     \end{itemize}
%     \item \textbf{HAR適用時の課題}：
%     \begin{itemize}
%         \item \textbf{音響・センサーデータへの適用性は未検証}
%         \item 主にマルチラベル画像分類タスクで評価されている
%         \item マルチラベルNon-IID: クラス分布だけでなく、\textbf{ラベルの共起や相関の分布もクライアント間で異なる}）という、より複雑なNon-IID問題に直接対応
%     \end{itemize}
% \end{itemize}
% \end{frame}

% \section{実装など}
% \begin{frame}{FedProx\cite{FedProx}}
% \begin{itemize}
%     \item FedProxを実装し,FedAvgと比較
%     \item flower+Dockerで実装を試みたが中断
%     \item Githubの検証用コードを利用: https://flower.ai/docs/baselines/fedprox.html
%     \item これから: 実行結果を配布ノートブックで可視化し,ローカルでの性能を検証
%     \item できれば: クライアント数を段階的に増やし,FedProxとFedAvgを比較 
% \end{itemize}
% \end{frame}

\begin{frame}{これから: マルチラベル分類}
\begin{itemize}
    \item 日常生活動作について、マルチラベル音響分類を検証
    \item 使用中の行動認識モデルはスペクトログラムを使うため,画像分類を参考にできそう
    \item 単純な分類を実装
    \begin{itemize}
        \item ESC-50データセットをマルチラベル用に加工、損失関数を変更
        \item cf. https://qiita.com/koshian2/items/ab5e0c68a257585d7c6f
    \end{itemize}
    \item より良い分類を実装
    \begin{itemize}
        \item 実装を探す: https://paperswithcode.com/task/multi-label-classificationなど
        \item Transformerでマルチラベル画像分類: https://github.com/SlongLiu/query2labels など参照
        \item 並行して異常イベント系のデータ収集/分析、モデル構築/検証が必要
    \end{itemize}
\end{itemize}
\end{frame}



\begin{frame}[allowframebreaks]{参考文献一覧}
  \small
  \begin{thebibliography}{9}

  \bibitem{FSL}
  J.~Ndeko, S.~Shaon, A.~Beal, A.~Sahoo, and D.~C.~Nguyen, 
  "Federated Split Learning for Human Activity Recognition with Differential Privacy," 
  \href{https://arxiv.org/abs/2411.06263}{arXiv:2411.06263}, 2024.

  \bibitem{sec}
  V.~Mothukuri \emph{et~al.},
  "A survey on security and privacy of federated learning," 
  \emph{Future Generation Computer Systems}, vol.~115, pp.~619–640, 2021. 
  \href{https://doi.org/10.1016/j.future.2020.10.007}{doi:10.1016/j.future.2020.10.007}.

  \bibitem{FedProx}
  T.~Li \emph{et~al.}, 
  "Federated Optimization in Heterogeneous Networks," 
  arXiv:1812.06127 [cs.LG, stat.ML], 2020.

  \bibitem{TBFL}
  S.~Park and M.~Elhilali, 
  "Time-Balanced Focal Loss for Audio Event Detection," ICASSP 2022, pp.~311–315.

  \bibitem{FMLL}
  B.~Ghasemkhani \emph{et~al.},
  "Federated Multi-Label Learning (FMLL): Innovative Method for Classification Tasks in Animal Science,"
  \emph{Animals}, vol.~14, no.~14, p.~2021, 2024.
  \href{https://doi.org/10.3390/ani14142021}{doi:10.3390/ani14142021}.

  \bibitem{FedMLP}
  Z.~Sun \emph{et~al.},
  "FedMLP: Federated Multi-label Medical Image Classification Under Task Heterogeneity,"
  \emph{Lecture Notes in Computer Science}, vol.~15010, pp.~394–404, 2024.
  \href{https://doi.org/10.1007/978-3-031-72117-5_37}{doi:10.1007/978-3-031-72117-5\_37}.

  \bibitem{FedLGT}
  I-Jieh Liu \emph{et~al.}, 
  "Language-Guided Transformer for Federated Multi-Label Classification," 
  arXiv:2312.07165, 2023.
  \url{https://arxiv.org/abs/2312.07165}

  \end{thebibliography}
\end{frame}

\end{document}